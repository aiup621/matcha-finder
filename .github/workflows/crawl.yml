name: crawl
on:
  schedule:
    - cron: "0 18 * * 1"  # 毎週月曜 03:00 JST（GitHubはUTC）
  workflow_dispatch:
jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Restore crawler cache
        uses: actions/cache@v4
        with:
            path: .cache
            key: cache-matcha-${{ runner.os }}-${{ hashFiles('requirements.txt', 'config/**') }}-${{ env.CACHE_VERSION || 'v1' }}
            restore-keys: |
              cache-matcha-${{ runner.os }}-
      - run: pip install -r requirements.txt
      - run: playwright install --with-deps chromium
      - name: Restore service account
        run: |
          echo '${{ secrets.SERVICE_ACCOUNT_JSON }}' > service_account.json
      - name: Run pipeline
        env:
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
          GOOGLE_CX: ${{ secrets.GOOGLE_CX }}
          SHEET_ID: ${{ secrets.SHEET_ID }}
          SKIP_SHEETS: "0"
        run: python pipeline.py
      - name: Save crawler cache
        if: always()
        uses: actions/cache@v4
        with:
            path: .cache
            key: cache-matcha-${{ runner.os }}-${{ hashFiles('requirements.txt', 'config/**') }}-${{ env.CACHE_VERSION || 'v1' }}
